{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage import segmentation\n",
    "from skimage import feature\n",
    "import scipy.ndimage as ndi\n",
    "import pandas as pd\n",
    "from cellpose import models\n",
    "import glob\n",
    "import tifffile\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = glob.glob('Data/*.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup SLURM cluster for Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://10.0.53.5:34107' processes=0 threads=0, memory=0 B>\n"
     ]
    }
   ],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "import dask\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    cores=2,                      # Number of cores per job\n",
    "    memory=\"128GB\",                # Memory per job\n",
    "    account=\"smc\",     # Project/account name\n",
    "    queue=\"gpu\",         # Queue/partition name\n",
    "    job_extra_directives =[\n",
    "        #'--gpus=1',  # Number of GPUs per job\n",
    "        '--gres=gpu:1',  # Number of GPUs per job\n",
    "    ],\n",
    "    walltime=\"02:00:00\",           # Job time limit\n",
    "    local_directory=\"$TMPDIR\",     # Temporary directory (optional)\n",
    "    log_directory=\"logs\",          # Directory for log files (optional)\n",
    ")\n",
    "\n",
    "client = Client(cluster)\n",
    "print(client)\n",
    "\n",
    "cluster.scale(jobs=4)  # Request 4 jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and run a simple image processing workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function a filename as an argument, performs cellpose segmentation on the last channel of the image, then calculates shape parameters and mean intensities for the first two channels.  The results are saved as a csv file with the same name as the input file, but with the extension changed to .csv.  A labels file is also saved with the cellpose results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(fname):\n",
    "    my_file = open(fname.replace('.tif', '.txt'), 'w')\n",
    "    my_file.write('Cuda available:  ' + str(torch.cuda.is_available()))\n",
    "    my_file.close()\n",
    "\n",
    "    model = models.Cellpose(gpu=True, model_type='cyto')\n",
    "    img = tifffile.imread(fname)\n",
    "    for idx in range(img.shape[0]):\n",
    "        img[idx] = np.clip(img[idx] - np.percentile(img[idx], 5), 0, np.percentile(img[idx], 100))\n",
    "    labels = model.eval(img[-1], diameter=200, channels=[0,0], flow_threshold=0.9, min_size=4000)[0]\n",
    "    df1 = pd.DataFrame(measure.regionprops_table(labels, img[1], properties=['label', 'area', 'centroid', 'eccentricity', 'major_axis_length', 'minor_axis_length', 'orientation', 'mean_intensity'])).rename(columns={'mean_intensity': 'mean_intensity1'})\n",
    "    df2 = pd.DataFrame(measure.regionprops_table(labels, img[2], properties=['mean_intensity'])).rename(columns={'mean_intensity': 'mean_intensity2'})\n",
    "    df = pd.concat([df1, df2], axis=1)\n",
    "    tifffile.imwrite(fname.replace('.tif', '_labels.tiff'), labels.astype(np.uint16))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run over all of the files in the list.  Can run this with and without dask/slurm to see the speedup advantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 851 ms, sys: 202 ms, total: 1.05 s\n",
      "Wall time: 59.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "using_dask = True\n",
    "all_data = []\n",
    "\n",
    "\n",
    "if using_dask:\n",
    "    delayed = dask.delayed(process_file)\n",
    "    for i, f in enumerate(fnames):\n",
    "        all_data.append(delayed(f))\n",
    "    all_data = dask.compute(*all_data)  \n",
    "    df = pd.concat(all_data)\n",
    "else:\n",
    "    for i, f in enumerate(fnames):\n",
    "        all_data.append(process_file(f))\n",
    "        print([np.floor(i*100.0/len(fnames)), f])\n",
    "    df = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De-allocate cluster resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
